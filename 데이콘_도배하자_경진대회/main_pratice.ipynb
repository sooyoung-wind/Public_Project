{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "import timm\n",
    "from timm import create_model\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Utils\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5581,  1.3625, -0.4348],\n",
       "         [-0.4470,  1.5754,  0.9783],\n",
       "         [ 0.6502, -1.2192,  1.4294]],\n",
       "\n",
       "        [[ 0.7953,  0.4238, -1.9113],\n",
       "         [ 0.3517,  1.6569,  0.9577],\n",
       "         [ 0.7508,  2.1028,  0.4501]],\n",
       "\n",
       "        [[-1.3490,  0.2560, -0.2655],\n",
       "         [ 0.3859,  0.7323,  0.0037],\n",
       "         [ 0.1820, -1.5374,  0.3087]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timm에서 사용할 수 있는 모델 리스트 불러오기\n",
    "size = (3,3,3)\n",
    "torch.randn(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9448, -0.9426,  1.3304],\n",
       "         [ 0.7952,  0.1989,  0.1005],\n",
       "         [ 0.1136, -1.4487, -1.2026]],\n",
       "\n",
       "        [[ 0.1708,  0.6990,  0.1465],\n",
       "         [ 0.9509, -0.8060,  0.4238],\n",
       "         [-1.4892,  1.8895,  0.7065]],\n",
       "\n",
       "        [[ 1.0684,  0.8743, -0.3099],\n",
       "         [-0.9624, -2.4079, -0.5602],\n",
       "         [-0.2960,  1.4314, -1.8829]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(*size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    " - 'Config' dictionary를 셍성합니다.\n",
    " - Python Script로 작성할 때 유용합니다.\n",
    " - Train 혹은 Inference 할 때 필요한 파라미터값들을 지정  \n",
    "   : Epochs, Batch Size, Learning Rate, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression expected after dictionary key and ':' (3781809392.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    'model': ,\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression expected after dictionary key and ':'\n"
     ]
    }
   ],
   "source": [
    "config ={\n",
    "    'model': ,\n",
    "    'model_save' : '/content/',\n",
    "    'data_path' : ,\n",
    "    'learning_rate': ,\n",
    "    'seed': 2023,\n",
    "    'img_size': ,\n",
    "    'n_epochs': ,\n",
    "    'ratio': ,\n",
    "    \"train_batch_size\": ,\n",
    "    \"valid_batch_size\": ,\n",
    "    \"min_lr\": ,\n",
    "    \"T_max\": ,\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./data/train\\\\가구수정\\\\0.png',\n",
       " './data/train\\\\가구수정\\\\1.png',\n",
       " './data/train\\\\가구수정\\\\10.png']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_img_list = glob.glob(\"./data/\" +'train/*/*')\n",
    "# all_img_list = glob.glob(config['data_path'] +'train/*/*')\n",
    "print(len(all_img_list))\n",
    "all_img_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/train\\\\걸레받이수정\\\\117.png'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = all_img_list[33]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3457, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train\\가구수정\\0.png</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/train\\가구수정\\1.png</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/train\\가구수정\\10.png</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/train\\가구수정\\11.png</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/train\\가구수정\\2.png</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   img_path label\n",
       "0   ./data/train\\가구수정\\0.png  data\n",
       "1   ./data/train\\가구수정\\1.png  data\n",
       "2  ./data/train\\가구수정\\10.png  data\n",
       "3  ./data/train\\가구수정\\11.png  data\n",
       "4   ./data/train\\가구수정\\2.png  data"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(columns=['img_path', 'label'])\n",
    "train['img_path'] = all_img_list\n",
    "train['img_path'].replace(\"\\\\\", \"/\")\n",
    "train['label'] = train['img_path'].apply(lambda x : str(x).split('/')[-2])\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/train/걸레받이수정/117.png'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 2223\n",
    "sample = train.img_path[num]\n",
    "image = cv2.imread(sample)\n",
    "print(\"Sample Image\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Encoding\n",
    " - Classification 문제이기 때문에, Target의 Class를 파악합니다.\n",
    " - Class를 0, 1, 2, 3, ... 으로 인코딩을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new_target'] = le.fit_transform(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>new_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train\\가구수정\\0.png</td>\n",
       "      <td>data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/train\\가구수정\\1.png</td>\n",
       "      <td>data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/train\\가구수정\\10.png</td>\n",
       "      <td>data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/train\\가구수정\\11.png</td>\n",
       "      <td>data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/train\\가구수정\\2.png</td>\n",
       "      <td>data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   img_path label  new_target\n",
       "0   ./data/train\\가구수정\\0.png  data           0\n",
       "1   ./data/train\\가구수정\\1.png  data           0\n",
       "2  ./data/train\\가구수정\\10.png  data           0\n",
       "3  ./data/train\\가구수정\\11.png  data           0\n",
       "4   ./data/train\\가구수정\\2.png  data           0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "data    3457\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_target\n",
       "0    3457\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.new_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = train.new_target.nunique()\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Seed\n",
    "\n",
    " > 실험적인 시도 혹은 Model Ensemble할 때 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set Seed\n",
    "set_seed(config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
