{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lWeb1H-MwEda"},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"Bi7MY-xGwEdc"},"source":["\n","# 컴퓨터 비전(Vision)을 위한 전이학습(Transfer Learning)\n","\n","**Author**: [Sasank Chilamkurthy](https://chsasank.github.io)\n","  **번역**: [박정환](http://github.com/9bow)\n","\n","이 튜토리얼에서는 전이학습(Transfer Learning)을 이용하여 이미지 분류를 위한\n","합성곱 신경망을 어떻게 학습시키는지 배워보겠습니다.\n","\n","    실제로 충분한 크기의 데이터셋을 갖추기는 상대적으로 드물기 때문에,\n","    (무작위 초기화를 통해) 맨 처음부터 합성곱 신경망(Convolutional\n","    Network) 전체를 학습하는 사람은 매우 적습니다. 대신, 매우 큰 데이터셋(예.\n","    100가지 분류에 대해 120만개의 이미지가 포함된 ImageNet)에서 합성곱\n","    신경망(ConvNet)을 미리 학습한 후, 이 합성곱 신경망을 관심있는 작업\n","    을 위한 초기 설정 또는 고정된 특징 추출기(fixed feature extractor)로 사용합니다.\n","\n","이러한 전이학습 시나리오의 주요한 2가지는 다음과 같습니다:\n","\n","-  **합성곱 신경망의 미세조정(finetuning)**: 무작위 초기화 대신, 신경망을\n","   ImageNet 1000 데이터셋 등으로 미리 학습한 신경망으로 초기화합니다. 학습의 나머지\n","   과정들은 평상시와 같습니다.\n","-  **고정된 특징 추출기로써의 합성곱 신경망**: 여기서는 마지막에 완전히 연결\n","   된 계층을 제외한 모든 신경망의 가중치를 고정합니다. 이 마지막의 완전히 연결된\n","   계층은 새로운 무작위의 가중치를 갖는 계층으로 대체되어 이 계층만 학습합니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ok0qnqwgwEdd"},"outputs":[],"source":["# License: BSD\n","# Author: Sasank Chilamkurthy\n","\n","from __future__ import print_function, division\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","\n","cudnn.benchmark = True\n","plt.ion()   # 대화형 모드"]},{"cell_type":"markdown","metadata":{"id":"P58V73YOwEde"},"source":["## 데이터 불러오기\n","\n","데이터를 불러오기 위해 torchvision과 torch.utils.data 패키지를 사용하겠습니다.\n","\n","여기서 풀고자 하는 문제는 **개미** 와 **벌** 을 분류하는 모델을 학습하는 것입니다.\n","개미와 벌 각각의 학습용 이미지는 대략 120장 정도 있고, 75개의 검증용 이미지가\n","있습니다. 일반적으로 맨 처음부터 학습을 한다면 이는 일반화하기에는 아주 작은\n","데이터셋입니다. 하지만 우리는 전이학습을 할 것이므로, 일반화를 제법 잘 할 수 있을\n","것입니다.\n","\n","이 데이터셋은 ImageNet의 아주 작은 일부입니다.\n","\n"]},{"cell_type":"code","source":["import zipfile\n","\n","os.system(\"wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\")\n","\n","def unzip_file(zip_path, extract_to):\n","    \"\"\"\n","    zip_path: 압축 해제할 ZIP 파일의 경로\n","    extract_to: 압축을 풀 폴더의 경로\n","    \"\"\"\n","    # 압축을 풀 폴더가 없으면 생성\n","    if not os.path.exists(extract_to):\n","        os.makedirs(extract_to)\n","\n","    # ZIP 파일 열기\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        # ZIP 파일 내용을 지정된 폴더에 압축 해제\n","        zip_ref.extractall(extract_to)\n","\n","# 사용 예시\n","zip_file_path = '/content/hymenoptera_data.zip'  # ZIP 파일 경로\n","destination_folder = '/content/data/'  # 압축 해제될 폴더 경로\n","\n","unzip_file(zip_file_path, destination_folder)"],"metadata":{"id":"QfnfBLehMPp6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mqx70soTwEde"},"outputs":[],"source":["# 학습을 위해 데이터 증가(augmentation) 및 일반화(normalization)\n","# 검증을 위한 일반화\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","data_dir = 'data/hymenoptera_data'\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'val']}\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n","                                             shuffle=True, num_workers=4)\n","              for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = image_datasets['train'].classes\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"STH6RTcewEde"},"source":["### 일부 이미지 시각화하기\n","데이터 증가를 이해하기 위해 일부 학습용 이미지를 시각화해보겠습니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OEN4DKfEwEdf"},"outputs":[],"source":["def imshow(inp, title=None):\n","    \"\"\"tensor를 입력받아 일반적인 이미지로 보여줍니다.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # 갱신이 될 때까지 잠시 기다립니다.\n","\n","\n","# 학습 데이터의 배치를 얻습니다.\n","inputs, classes = next(iter(dataloaders['train']))\n","\n","# 배치로부터 격자 형태의 이미지를 만듭니다.\n","out = torchvision.utils.make_grid(inputs)\n","\n","imshow(out, title=[class_names[x] for x in classes])"]},{"cell_type":"markdown","metadata":{"id":"rHInsij2wEdf"},"source":["## 모델 학습하기\n","\n","이제 모델을 학습하기 위한 일반 함수를 작성해보겠습니다. 여기서는 다음 내용들을\n","설명합니다:\n","\n","-  학습률(learning rate) 관리(scheduling)\n","-  최적의 모델 구하기\n","\n","아래에서 ``scheduler`` 매개변수는 ``torch.optim.lr_scheduler`` 의 LR 스케쥴러\n","객체(Object)입니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W8dT9EMKwEdf"},"outputs":[],"source":["def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        print('-' * 10)\n","\n","        # 각 에폭(epoch)은 학습 단계와 검증 단계를 갖습니다.\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # 모델을 학습 모드로 설정\n","            else:\n","                model.eval()   # 모델을 평가 모드로 설정\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # 데이터를 반복\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # 매개변수 경사도를 0으로 설정\n","                optimizer.zero_grad()\n","\n","                # 순전파\n","                # 학습 시에만 연산 기록을 추적\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # 학습 단계인 경우 역전파 + 최적화\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # 통계\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            # 모델을 깊은 복사(deep copy)함\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best val Acc: {best_acc:4f}')\n","\n","    # 가장 나은 모델 가중치를 불러옴\n","    model.load_state_dict(best_model_wts)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"ZWgaq5g9wEdg"},"source":["### 모델 예측값 시각화하기\n","\n","일부 이미지에 대한 예측값을 보여주는 일반화된 함수입니다.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oH6cAmSGwEdg"},"outputs":[],"source":["def visualize_model(model, num_images=6):\n","    was_training = model.training\n","    model.eval()\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders['val']):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for j in range(inputs.size()[0]):\n","                images_so_far += 1\n","                ax = plt.subplot(num_images//2, 2, images_so_far)\n","                ax.axis('off')\n","                ax.set_title(f'predicted: {class_names[preds[j]]}')\n","                imshow(inputs.cpu().data[j])\n","\n","                if images_so_far == num_images:\n","                    model.train(mode=was_training)\n","                    return\n","        model.train(mode=was_training)"]},{"cell_type":"markdown","metadata":{"id":"yCljW61ewEdg"},"source":["## 합성곱 신경망 미세조정(finetuning)\n","\n","미리 학습한 모델을 불러온 후 마지막의 완전히 연결된 계층을 초기화합니다.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTyHdGUrwEdg"},"outputs":[],"source":["model_ft = models.resnet18(weights='IMAGENET1K_V1')\n","num_ftrs = model_ft.fc.in_features\n","# 여기서 각 출력 샘플의 크기는 출력 크기로 설정합니다.\n","model_ft.fc = nn.Linear(num_ftrs, #TODO)\n","\n","model_ft = model_ft.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# 모든 매개변수들이 최적화되었는지 관찰\n","optimizer_ft = optim.SGD(model_ft.parameters(), lr=#TODO, momentum=0.9)\n","\n","# 7 에폭마다 0.1씩 학습률 감소\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"]},{"cell_type":"markdown","metadata":{"id":"9iGJfd7nwEdg"},"source":["### 학습 및 평가하기\n","\n","CPU에서는 15-25분 가량, GPU에서는 1분도 이내의 시간이 걸립니다.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"swrkSwOiwEdg"},"outputs":[],"source":["model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n","                       num_epochs=#TODO)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMFwFGPFwEdh"},"outputs":[],"source":["visualize_model(model_ft)"]},{"cell_type":"markdown","metadata":{"id":"WlgJUs3gwEdh"},"source":["## 고정된 특징 추출기로써의 합성곱 신경망\n","\n","이제, 마지막 계층을 제외한 신경망의 모든 부분을 고정해야 합니다.\n","``requires_grad = False`` 로 설정하여 매개변수를 고정하여 ``backward()`` 중에\n","경사도가 계산되지 않도록 해야합니다.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HG1thcD5wEdi"},"outputs":[],"source":["model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n","for param in model_conv.parameters():\n","    param.requires_grad = False\n","\n","# 새로 생성된 모듈의 매개변수는 기본값이 requires_grad=True 임\n","num_ftrs = model_conv.fc.in_features\n","# 여기서 각 출력 샘플의 크기는 출력 크기로 설정합니다.\n","model_conv.fc = nn.Linear(num_ftrs, #TODO)\n","\n","model_conv = model_conv.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# 이전과는 다르게 마지막 계층의 매개변수들만 최적화되는지 관찰\n","optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n","\n","# 7 에폭마다 0.1씩 학습률 감소\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"]},{"cell_type":"markdown","metadata":{"id":"IOLDBgfRwEdi"},"source":["### 학습 및 평가하기\n","\n","CPU에서 실행하는 경우 이전과 비교했을 때 약 절반 가량의 시간만이 소요될 것입니다.\n","이는 대부분의 신경망에서 경사도를 계산할 필요가 없기 때문입니다. 하지만,\n","순전파는 계산이 필요합니다.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YuOCHoexwEdi"},"outputs":[],"source":["model_conv = train_model(model_conv, criterion, optimizer_conv,\n","                         exp_lr_scheduler, num_epochs=25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"latW-YKswEdi"},"outputs":[],"source":["visualize_model(model_conv)\n","\n","plt.ioff()\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[{"file_id":"https://github.com/PyTorchKorea/tutorials-kr/blob/master/docs/_downloads/74249e7f9f1f398f57ccd094a4f3021b/transfer_learning_tutorial.ipynb","timestamp":1700534440541}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}