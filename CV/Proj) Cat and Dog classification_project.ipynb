{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5ovwmgwNuM7g"},"source":["# Image Classification\n","\n","모델이 데이터를 효율적으로 학습할 수 있도록 구현해보는게 목적입니다.\n","\n","* Data augmentation을 이용해 오버피팅을 방지해봅시다.\n","\n","기본적인 머신러닝 작업과정은 아래와 같습니다.\n","\n","1. Examine and understand data\n","2. Build an input pipeline\n","3. Build the model\n","4. Train the model\n","5. Test the model\n","6. Improve the model and repeat the process\n","\n","* 모델 완성 후 평가 지표에 따라서 모델을 평가해 봅시다."]},{"cell_type":"markdown","metadata":{"id":"gtOh3dJctz6k"},"source":["## Project 설명\n","### Task\n","* 적은 수의 강아지와 고양이 사진을 이용해 classification을 진행해보자.\n","* 주어진 데이터를 Augmentation 하는 법과 딥러닝 트레이닝 과정을 구현해 보는것이 목표입니다.\n","* 데이터셋은 학습 데이터엔 강아지, 고양이 이미지 1000장이 있고, 테스트용 데이터에는 각각 500장씩 주어져있습니다.\n","    * 트레이닝 시 image size 조절해 사용\n","\n","### Baseline\n","* 기본적으로 사용하는 Convolution layers를 구성해 사용해보자.\n","* 오버피팅을 방지하기 위한 다양한 방법들을 사용해보자.\n","    * Data Augmentation, Dropout, Batch Normalization\n","* Training\n","* Evaluation\n","    * 모델의 정확도와 크기를 이용해 점수를 제공하는 메트릭으로 평가해보자."]},{"cell_type":"markdown","metadata":{"id":"bjyhZYgLnBxL"},"source":["### Import packages\n","\n","* 우리가 사용할 packages 를 import 하는 부분 입니다.\n","* 필요에 따른 packages를 선언합니다.\n","* 모델 저장을 위해서 구글 드라이브를 마운트해줍니다."]},{"cell_type":"code","metadata":{"id":"T_K_gTJMuM7j"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader\n","import torchvision\n","from torchvision import datasets, models, transforms\n","\n","import os\n","import requests\n","import zipfile\n","import time\n","import copy\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jNzGW0WIKrTd"},"source":["use_colab = True\n","assert use_colab in [True, False]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mgio5jXjyVOt"},"source":["### 데이터셋 다운로드\n","\n","* 해당 데이터는 개와 고양이 데이터로 구성되어 있습니다."]},{"cell_type":"code","metadata":{"id":"MTaZderogWxy"},"source":["def download_and_extract(url, dest_path):\n","    # 파일 이름 추출\n","    filename = url.split('/')[-1]\n","    file_path = os.path.join(dest_path, filename)\n","\n","    # 파일이 이미 존재하지 않는 경우 다운로드\n","    if not os.path.exists(file_path):\n","        response = requests.get(url)\n","        with open(file_path, 'wb') as file:\n","            file.write(response.content)\n","\n","    # 파일이 zip 파일인 경우 압축 해제\n","    if file_path.endswith('.zip'):\n","        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n","            zip_ref.extractall(dest_path)\n","\n","# 사용 예시\n","_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n","download_and_extract(_URL, './')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rQ2hgNc_nfLg"},"source":["### cats_and_dogs_filtered\n","* |__ train\n","    * |______ cats: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n","    * |______ dogs: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n","* |__ validation\n","    * |______ cats: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n","    * |______ dogs: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]"]},{"cell_type":"markdown","metadata":{"id":"Nb4kBkjd6cYE"},"source":["# 데이터셋 설정\n","* 다운로드 받은 데이터셋에 대한 경로를 이용하여, 데이터를 이용할 준비를 진행합니다."]},{"cell_type":"code","metadata":{"id":"G88NI3nYuM7q"},"source":["PATH = '/content/cats_and_dogs_filtered'\n","train_dir = os.path.join(PATH, 'train')\n","validation_dir = os.path.join(PATH, 'validation')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6JDmNp3juM7u"},"source":["# directory with our training cat pictures\n","train_cats_dir = os.path.join(train_dir, 'cats')\n","\n","# directory with our training dog pictures\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","\n","# directory with our validation cat pictures\n","validation_cats_dir = os.path.join(validation_dir, 'cats')\n","\n","# directory with our validation dog pictures\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dARbrBlfHnip"},"source":["* 데이터셋의 구성을 살펴봅시다."]},{"cell_type":"code","metadata":{"id":"7asbu69MuM7x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700574568324,"user_tz":-540,"elapsed":7,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"48e652ee-5e15-4d8a-c721-7f624a4841b7"},"source":["num_cats_tr = len(os.listdir(train_cats_dir))\n","print('total training cat images:', num_cats_tr)\n","num_dogs_tr = len(os.listdir(train_dogs_dir))\n","print('total training dog images:', num_dogs_tr)\n","\n","print(\"--\")\n","\n","num_cats_val = len(os.listdir(validation_cats_dir))\n","print('total validation cat images:', num_cats_val)\n","num_dogs_val = len(os.listdir(validation_dogs_dir))\n","print('total validation dog images:', num_dogs_val)\n","\n","print(\"--\")\n","\n","total_train = num_cats_tr + num_dogs_tr\n","print(\"Total training images:\", total_train)\n","total_val = num_cats_val + num_dogs_val\n","print(\"Total validation images:\", total_val)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total training cat images: 1000\n","total training dog images: 1000\n","--\n","total validation cat images: 500\n","total validation dog images: 500\n","--\n","Total training images: 2000\n","Total validation images: 1000\n"]}]},{"cell_type":"markdown","metadata":{"id":"KFfWm7_wHq6Q"},"source":["* 학습 데이터는 고양이와 강아지 이미지 각각 1000 장씩으로 구성되어있습니다.\n","* 모델 평가를 위해서 각각 500장씩을 validation dataset으로 사용합니다."]},{"cell_type":"markdown","metadata":{"id":"zIEiuF_u7KDn"},"source":["### Data preparation 데이터 준비\n"]},{"cell_type":"code","source":["# 학습을 위해 데이터 증가(augmentation) 및 일반화(normalization)\n","# 검증을 위한 일반화\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","    ]),\n","    'validation': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","    ]),\n","}\n","\n","data_dir = '/content/cats_and_dogs_filtered'\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'validation']}\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n","                                             shuffle=True, num_workers=4)\n","              for x in ['train', 'validation']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}\n","class_names = image_datasets['train'].classes\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"V8ymdJWRJ1Ci"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UT4YTPRbzokO"},"source":["### 이미지 샘플 확인"]},{"cell_type":"code","source":["def imshow(inp, title=None):\n","    \"\"\"tensor를 입력받아 일반적인 이미지로 보여줍니다.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # 갱신이 될 때까지 잠시 기다립니다.\n","\n","\n","# 학습 데이터의 배치를 얻습니다.\n","inputs, classes = next(iter(dataloaders['train']))\n","\n","# 배치로부터 격자 형태의 이미지를 만듭니다.\n","out = torchvision.utils.make_grid(inputs)\n","\n","imshow(out, title=[class_names[x] for x in classes])"],"metadata":{"id":"Ebqq8Na9Kzd-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ri70-ylUz_Bl"},"source":["# 모델 구현\n","\n","* 직접 구현을 진행하거나 Transfer Learning을 진행할 수 있습니다.\n"]},{"cell_type":"code","metadata":{"id":"--dStHdvuM8W"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R5eVZ_Rs0B-1"},"source":["# 모델 학습 진행\n","* 학습을 진행할때, train과 valid 데이터셋을 이용하여 학습과 검증을 동시에 진행합니다.\n","* 각 데이터셋은 위에서 구성했기 때문에, 모델에서 사용할 데이터의 step의 길이를 batch_size를 이용해 계산해줍니다."]},{"cell_type":"code","source":[],"metadata":{"id":"PXdhXm541mNN"},"execution_count":null,"outputs":[]}]}